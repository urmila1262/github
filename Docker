                           docker build              docker run
Developer ----->dockerfile ----->build docker image ---->docker container(will have all applications and dependencies)
                                                     docker push                                                               pull image
                                                    ----> also stored in online cloud repository called "docker hub".--->docker image--->docker container
                            

What is Docker?

Docker is a tool designed to make it easier to create, deploy, and run applications by using containers. 
Containers allow a developer to package up an application with all of the parts it needs, such as libraries and other dependencies, and deploy it as one package.

Advantages of Docker?

Build app only once : An application inside a container can run on any system that has docker installed.So there is no need to build and configure application 
multiple times on different platforms.
More sleep and less worry : With docker you test your application inside a container and ship it inside a container. This means the environment 
in which you test is identical to the one on which the application will run in production.
portability: Docker containers will run on any platform. It can run on any local system,Amazon EC2,Google cloud,Rackspace server,Virtual box etc 
Version control: Like GIT, Docker has inbuilt version control system. Docker containers work just like GIT repositories,allowing you to commit changes to 
your docker images and version control them.
Isolation: With docker every application works in isolation in its own container and doesnot interferes with other applications running on the same system.
so we can run multiple containers and to remove we can simply delete containers.
Productivity: Increases productivity and efficiency without worrying about platforms.

What is diff b/w docker and kubernetes?

Docker is a platform and tool for building, distributing, and running Docker containers. ... Kubernetes is a container orchestration system for Docker containers 
that is more extensive than Docker Swarm and is meant to coordinate clusters of nodes at scale in production in an efficient manner.

what is an image in Docker?

Docker images are templates used to create containers that can run on the Docker platform.Container is a running instance of image.
Images --->Binaries ,dependencies and metadata.

18. What is Hypervisor?

The hypervisor is a software which allows you to create a virtual environment in which the guest virtual machines operate. 
It controls the guest systems and checks if the resources are allocated to the guests as necessary.

---- Diff b/w Docker and virtualization?

Virtual Machine	                                                               Docker Container

Hardware-level process isolation	                                             OS level process isolation
Each VM has a separate OS	                                                     Each container can share OS
Boots in minutes	                                                             Boots in seconds
VMs are of few GBs	                                                           Containers are lightweight (KBs/MBs)
Ready-made VMs are difficult to find	                                         Pre-built docker containers are easily available
VMs can move to new host easily	                                               Containers are destroyed and re-created rather than moving
Creating VM takes a relatively longer time	                                   Containers can be created in seconds
More resource usage	                                                           Less resource usage

---- What is docker file?
Dockerfile --describes steps to create a docker image. All applications,dependencies are defined in a dockerfile to build docker image.

----What is docker demon and engine?
Docker Engine is the core product of Docker, including its daemon (dockerd) as well as its CLI (docker). Docker Daemon is simply a part of Docker Engine.

Docker Engine is an open source containerization technology for building and containerizing your applications. Docker Engine acts as a client-server application with:

A server with a long-running daemon process dockerd.
APIs which specify interfaces that programs can use to talk to and instruct the Docker daemon.
A command line interface (CLI) client docker.

---What is copy and add in dockerfile?

COPY and ADD are both Dockerfile instructions that serve similar purposes. They let you copy files from a specific location into a Docker image.

COPY takes in a src and destination. It only lets you copy in a local file or directory from your host (the machine building the Docker image)
into the Docker image itself.

ADD lets you do that too, but it also supports 2 other sources. First, you can use a URL instead of a local file / directory. 
Secondly, you can extract a tar file from the source directly into the destination.



CONTAINER:12

 # docker version ---->Gives the information of client,server(engine) of docker.
 # docker -v (or) # docker --version ---->gives version info.
 # sudo service docker start ---->to start docker deamon
 # sudo service docker stop ---->stops docker
 # sudo yum remove docker ---->uninstalls docker 
 # docker info  ---->Gives the detailed information more than docker version.
 # docker login ---> to login to docker hub from terminal.
 # docker system df ----> to see disk usage of containers,images,volumes etc.
 # sudo usermod -a -G docker <username> ----> to add a user to Docker so that we can execute all commands on our user without sudo.
## syntax: docker <command> <subcommand> (options).
 # docker container run --publish 80:80 nginx --->downloads the nginx image from docker hub and runs.
 # docker create (image). ----->create a container(without starting it).
 # docker rename oldcon newcon ---->renames the old container name.
 # docker run (image) (command) ---->run a command in a new container
 # docker run --rm (image). ----> removes the container after it exits
 # docker run -td (image) ---->starts a container and keeps it running
 # docker run -it [IMAGE] –--> starts a container and creates an interactive bash shell in the container.
 # docker run -it-rm [IMAGE] –---> creates, starts, and runs a command inside the container. Once it executes the command, the container is removed.
 # docker rm [CONTAINER] ---->Delete a container (if it is not running).
 # docker update [CONTAINER]----> Update the configuration of one or more containers.
 # docker start [CONTAINER] ---->Start a container.
 # docker stop [CONTAINER] ----->Stop a running container.
 # docker restart [CONTAINER] --->Stop a running container and start it up again.
 # docker pause [CONTAINER] ----> Pause processes in a running container.
 # docker unpause [CONTAINER] ---->Unpause processes in a running container.
 # docker wait [CONTAINER] ----> Block a container until others stop (after which it prints their exit codes)
 # docker kill [CONTAINER] ---> Kill a container by sending a SIGKILL to a running container.
 # docker attach [CONTAINER] --->Attach local standard input, output, and error streams to a running container.
 
 # docker container ls ---->shows all running containers  # docker ps --->old
 # docker container ls -a ----> show all running and stopped containers  # docker ps -a ----> old
 # docker container logs ID ----> Opens logs of particular container.  # docker logs [CONTAINER] --->old
 # docker inspect [OBJECT_NAME/ID] ----> lists low level information on Docker objects.
 # docker events [CONTAINER]---->List real-time events from a container
 # docker port [CONTAINER] ---->Show port (or specific) mapping for a container
 # docker top [CONTAINER] ---->Show running processes in a container
 # docker stats [CONTAINER] ---->Show live resource usage statistics of containers
 # docker diff [CONTAINER] ----->Show changes to files (or directories) on a filesystem
 # 
 

IMAGES:

 # docker image ls ---> gives list of existing images in our docker.
 # docker images -q --->gives only image ID
 # docker images -f "dangling=false" ---->it will filter all dangling images.(untagged)
 # docker pull nginx ---> It will download the latest image of nginx.
 # docker pull nginx:1.11 --->it will download the specific defined version of nginx. (here 1.11 is a tag).
 # docker pull nginx:1.11-alpine ---> it will download alpine supported nginx which is very small container of unix os.
 # docker history nginx:latest ---> it will give history of nginx image layers. (this command works for the images only exits in our docker)
 Note: Every layer is having its own unique SHA and the files will be stored once in images they will be accessed.
 # docker history mysql ----> Shows history of an image
 # docker history mysql:latest
 # docker image inspect nginx ---> it will gives the metadata of the nginx image.(image ID,tags,exposed ports,env variables and how the image expects to be run etc)
 
 Tags are labels point to the image ID.
 # docker image tag sourceimage(:tag) targetimage(tag) --->syntax.
 # docker image tags --help ---> it will give syntax to use tags.
 # docker image ls --->we can see tags here only
 # docker image tag nginx urmila/nginx ---->way to change the original tag and use our own.
 # docker image ls ---> now you can see the new image with our own tag but image ID is same for both.
 # docker image push urmila/docker ---> used to push our image to docker hub.
 # docker --help ---> gives options to use.
 # docker login ---> ask credentials to login to docker hub.
 # cat .docker/config.json ---> config file contains authentication token(need to be careful when using shared accouts)
 
DOCKER FILE:

Step:1 Create a file named Dockerfile. # vim Dockerfile
Step:2 Add instructions in Dockerfile
Step:3 Build Dockerfile to create image
Step:4 Run image to create container.

# getting base image docker --->comment
FROM ubuntu --->image name

RUN apt-get update ---->running ubuntu

CMD ["echo","Hello World...! from my first docker image"] ---->running cmd inside ubuntu.

  # docker run efc34aa ----> it will runs our container.
  
References:
https://github.com/wsargent/docker-ch...​
https://docs.docker.com/engine/reference/builder/



 # docker image build -t customnginx .   ----> build the docker image based on docker file steps and it will stores all info in cache and uses it when we run the
   build next time.
 # docker container run -p 80:80 --rm nginx ---> to run the container in normal way.
 # docker image build -t nginx-with-html ---->by running as a build it will be faster becoz stored in cache.
 Note: Now we can create tag to this image and push into our own docker hub.
 # docker import [URL/FILE] ---->Create an image from a tarball.
 # docker commit [CONTAINER] [NEW_IMAGE_NAME] ---->Create an image from a container.
 # docker rmi [IMAGE] ---->Remove an image.
 
 We can build our own dockerfile and run container on it.
 By modifying existing docker file we can say expose on what ever port we want, do changes as our wish and run the container, then we can tag it and push into our
 docker hub.
 # docker push [options] name[:tag] ---> syntax.
 # docker image ls ---> lists our image
 # docker image rm imagetagname ---> it will removes our image from cache need to download again if you want.
 
 Using Prune to Keep Your Docker System Clean (YouTube)
You can use "prune" commands to clean up images, volumes, build cache, and containers. Examples include:

- docker image prune --->to clean up just "dangling"(not associated with running container) images

- docker system prune ----> will clean up everything ( -f force

- The big one is usually # docker image prune -a -->which will remove all images you're not using. Use # docker system df ---> to see space usage.

Remember each one of those commands has options you can learn with --help.

Here's a YouTube video I made about it: https://youtu.be/_4QzP7uwtvI

Lastly, realize that if you're using Docker Toolbox, the Linux VM won't auto-shrink. You'll need to delete it and re-create (make sure anything in
docker containers or volumes are backed up). You can recreate the toolbox default VM with # docker-machine rm default   and then # docker-machine create

NETWORK:

# docker network ls --->lists network
# docker network rm [NETWORK] ---->Remove one or more networks
# docker network inspect [NETWORK] ---->Show information on one or more networks
# docker network connect [NETWORK] [CONTAINER] ---->Connects a container to a network
# docker network disconnect [NETWORK] [CONTAINER]. ---->Disconnect a container from a network

---- Difference between run command and entry point?   
---- docker file for nginx and tomcat?
what is conterziation









####################


# docker run postgres:9.6 --->run postgres SQL of 9.6 version
# docker ps ---> see all running containers

Docker image: Image is the actual package that contains all dependencies and configurations, artifact that can be moved around.(not running)
Docker container: Pull that image and actually start the application to run on local machine that creates a container environment.(running)  
(or) container is a running environment for image.

Note: Container has a port which is useful to talk to the application running inside the container and container has its own file system which is diff from 
file system of host.

Docker hub: contains all images along with afficial images.


Docker                                     VM

Applications } vertualises apps           Applications }vertualises both apps and kernal
os kernal                                 os kernal
Hardware                                  Hardware

Adv: size:Docker images are smaller in size
speed: docker containers start and run much faster
Compatability: VM of any OS can run on any OS host, but can't do with docker

Basic commands:

# docker pull redis --->pull from docker hub
# docker images  --->list all images
# docker run redis ---> runs images called container.
# docker ps     ------>lists all running containers , ctrl+c to terminate
# docker run -d redis ----> to run in detach mode, gives ID
# docker ps --->gives container running with ID
# docker stop (ID of container) --->stops container
# docker start (ID of container) --->again starts the container
# docker ps -a --->list all stopped and running containers
# docker run redis:4.0 ---> it will pull and run the 4.0 version of redis.
# docker ps ---> two containers are running

Note: Here two docker contaners will be running with same container port but it should be diff with host port no:

# docker run -p6000:6379 redis  ---> binding the container port to host port and here 6000 is host port and 6379 container and redis particular container name.
# docker ps ---> under ports we can see the binding
# docker run -p6000:6379 -d redis --->running in detach mode
# docker run -p6001:6379 redis:4.0 ---> other container running on diff host port, even we specify same port it will through error alreay port is allocated.
# docker run -p6001:6379 -d redis:4.0 --->running in detach mode.

Docker debugging:

# docker logs container ID ---> gives logs of the specified container
But it will be difficult to remember container ID all the time so we can specify name of container as well
# docker logs containername ---> this also gives logs of container

Note: when we run the container it will come with some random name but we can specify our own name to the container.Before giving name to the cotainer we need to 
stop the container.
# docker run -d -p6001:6379 --name redis-older redis:4.0 --->here redis-older is specified name
# docker ps ---> will give container name specified and port etc

Note: with docker exec we can get the terminal of the docker container, so we can check log file,config file or env variables etc
# docker exec -it containerID /bin/bash ---> -it (interactive terminal) and this command will open bash terminal, inside terminal with root user. Here we can give
container name as well instead of container ID.

Now treminal is open we can check pwd,home,env,usr,lib,bin etc files, we can simply exit from terminal with exit command. Mostly all the containers are run with 
light weight linux so, we can't see curl and few more commands but available commands are enough for debugging.

Docker run and Docker start:

Docker run: Where we can create new container from image and will specify -d -p --name all options. It will work with images and it will be used only at time of 
container creation.
Docker start: Docker start will work with containers, when container started it will runs with all attributes defined at the time of creation and mainly it 
will restart stopped containers.

Development env:

# docker pull mongo
# docker pull mongo-express
# docker images

Next step is to run the mongo db and express need to estabilsh connection of mongo express with mongo db.

Docker Network: 

Docker provides an isolated Docker network where the containers are running, when you deploy two containers in same docker network they can talk to each other 
just with the container name with out port no: etc, but the nodeJS will connect with them from outside by using localhost and portno:

Docker provides some auto generated Networks

# docker network ls  --->gives list of default networks
# docker network create mongo-network ---->to create our own network

Note: Now we can run our containers mongo db and mongo express in the mongo network by specifying its name at the time of creation of containers.

# docker run -p 27017:27017 -d -e MONGO_INITDB_ROOT_USERNAME=admin -e MONGO_INITDB_ROOT_PASSWORD=password --name mongodb --net mongo-network mongo

To create the containers inside the n/w we need to specify the env variables,default port no: of mongodb is 27017, name of container,name of network and image 
name.

To simplify above query:
# docker run -d \
> -p 27017:27017 \
> -e MONGO_INITDB_ROOT_USERNAME=admin \
> -e MONGO_INITDB_ROOT_PASSWORD=password \
> --name mongodb \
> --net mongo-network \
> mongo

# docker logs container ID --->gives logs whats happening.

For docker express also we can check configuration variables
# docker run -d \
> -p 8081:8081 \
> -e ME_CONFIG_MONGODB_ADMINUSERNAME=admin \
> -e ME_CONFIG_MONGODB_ADMINPASSWORD=password \
> --net mongo-network \
> --name mongo-express \
> -e ME_CONFIG_MONGODB_SERVER=mongodb \  --->here this will connect to mongodb(docker ps will give container name)
> mongo-express

connect with node JS:

code

# docker logs containerID | tail --->last 10 lines of logs default
# docker logs containerID -f ---> string the logs

Docker compose:

Docker compose is used to run multiple docker containers. when we have 10 docker containers and trying to connect with each it will be difficult to run this
above command for all so we are using docker compose.

.yaml file: for mongo db

-----
version:'3'  --->version of docker compose
services:    ---> list goes from here
   mongodb:  ---->container name
     image:mongo --->image name from docker hub, and you can include version tag as well if required.
     ports:
      -27017:27017  --->host:container
     environment:
      -MONGO..._USERNAME=ADMIN
     
-----

This is docker compose for one specific container.

.yaml file: for mongo express

-----
version:'3'
services:
   mongodb:
     image:mongo
     
     ...
   mongo-express:
   
     image:mongo-express
     ports:
      -8081:8081
   environment:
    -ME_CONFIG_MONGODB_A....
    ...
-----

Note: Here no need to specify the docker network, docker compose will take care in which n/w identical containers should run.

Create docker compose file:
 -------
 version: '3'
 services:
  mongodb:
    image: mongo
    ports:
      - 27017:27017
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password
  mongo-express:
    image: mongo-express
    ports:
      - 8080:8081
    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=admin
      - ME_CONFIG_MONGODB_ADMINPASSWORD=password
      - ME_CONFIG_MONGODB_SERVER=mongodb

 -------
 
 Docker compose is already installed with Docker.
 
 # docker-compose -f Docker-compose.yaml up  ---> here "f" is file  "up" will run the comtainers inside docker-compose.
 
 Note: this will create both containers in the default network, here we can observed that the mongo express will connect after mongodb starts.
 
 # docker network ls --->gives all the n/ws
 # docker ps --->to see containers running and they will run on specified ports and with names.
 
 Note: Here when this containers restarts, the data will be lost in containers but for the data persistance in container we can use volumes.
 
 
 # docker-compose -f Docker-compose.yaml down  ----> "down" option will stops all the containers in docker compose.
 
 Note: To stop docker containers need to specify each container name every time but with docker compose it is quite simple with above command, but it will
 stop and removes the containers and network as well, when we again start docker-compose it will re-creates the containers and network.
 
 # docker-compose -f Docker-compose.yaml up -d --->run as demon and creates containers and n/w.
 
 
 Dockerfile:
 
 Note: Generally we can write java script by using node.js and commit changes to git repository then CI tool Jenkins will build the package(image) and push 
 it to docker hub(repository).
 
 What is docker file?
 Docker file is a blueprint for creating docker images.
 
 Docker file:
 ----
 FROM node(image)  --->install node
 ENV MONGO_DB_USERNAME=admin \
     MONGO_DB_PWD=password       ----->set username and password
 RUN mkdir -p /home/app   ---->create a /home/app folder, using run you can execute any linux command.(* This dir is created inside of the container)
 COPY . /home/app  --->copy current folder files from local host to the container /home/app folder.
 CMD["node","server.js"] ---> start the app with: "node server.js",this is always part of docker file but CMD will execute the basic command linux entry point.
 ----
 Note:All the steps in docker file will effect the container but not our host.
 
 Difference between RUN and CMD?
 CMD = entrypoint command (only one linux command), you can have multiple RUN commands with linux commands but CMD is one that marks dockerfile this is the 
 entrypoint that you have to execute as entrypoint.
 
 Difference between CMD and entrypoint?
 ENTRYPOINT: command to run when container starts. 
 CMD: command to run when container starts or arguments to ENTRYPOINT if specified.
 
 Note: Every image (docker file) takes the basic image from docker hub.
 
 
 
 Dockerfile:  Name of the docker file should be with capital "D"
 ------
 FROM node:13-alpine
 
 ENV MONGO_DB_USERNAME=admin \
     MONGO_DB_PWD=password
     
 RUN mkdir -p /home/app
 
 COPY . /home/app
 
 CMD ["node", "server.js"]
 ------
 
 Build docker image with docker file:
 
 # docker build -t my-app:1.0 .
 
 Note: docker build require two parameters my-app is our image name and its version then second is where to create docker image here its in current dir.
 The image is build and it will generate the ID.
 
 # docker images   ---->will see our image with name,tag and ID.
 
 Start my-app container to verify:
 > app start successfully.
 > app environment is configured correctly.
 
 # docker run my-app:1.0
 
 Error: server.js not found, becoz we copyed every thing to /home/app dir.
 
 ------
 FROM node:13-alpine
 
 ENV MONGO_DB_USERNAME=admin \
     MONGO_DB_PWD=password
     
 RUN mkdir -p /home/app
 
 COPY . /home/app
 
 CMD ["node", "/home/app/server.js"]
 ------
 
 Note: When you adjust the Dockerfile, you must rebuild the image.
 
 # docker rmi imageID ---> first need to remove the image that has built already and rebuild. But before removing image, container need to remove.
 # docker ps -a | grep my-app
 # docker rm containerID
 # docker rmi imageID --->now image is removed
 # docker images     ----> our docker image not exist.
 # docker build -t my-app:1.0 ---->rebuild the docker image.
 # docker images  ----> to see our image from list of images
 # docker run my-app:1.0   ----> to run our container. We got app listening on port 3000.
 
 To check take containerID
 # docker ps  ---->will get containerID from list of containers.
 # docker logs containerID  ---> app listening on port 3000.
 
 # docker exec -it contID /bin/bash  ---> some container doesn't have bash they can be executed with shell
 # docker exec -it contID /bin/sh   ----> now terminal opens
 /# ls   ---> inside the container it will list all the dirs.
 /# env  ---> we will find the env variables declared by us.
 /# ls /home/app/  ---> the dir created and it has copy of current dir.
 /# exit
 
 To modify the Dockerfile need to follow all below steps to build the image again.
 
 # docker images
 # docker ps
 # docker stop contID
 # docker rm contID
 # docker rmi imageID
 # docker images
 # docker build -t my-app:1.0 .   ----> First need to go to the particular dir and execute this command.
 # docker images
 # docker run my-app:1.0  ----> Run the container and now we can run in detatched mode.
 # docker ps
 # docker exec -it containerID /bin/sh
 /# ls  ---> will see the list of files in the pwd.
 /# ls /home/app   ----> we can see what all the folders we have added to the app dir.
 /# exit
 
 
 Private Docker repository:
 
 We can create docker private registory on Amazon AWS ECR,nexus etc
 > Docker private repository
 > Registry options
 > Build and tag an image
 > docker login
 > docker push
 
 Create private docker repository on AWS:
 
 First we need to create private docker repository also called registry.
 In AWS account use Elastic Container Registry (ECR)  ---> repositories ---> create repository (give name of repository which is same as imagename i.e my-app)
 ---> click create repository (repository is created successfully with name my-app)
 In AWS per each image we have to create the repository rather than pushing all images related to multiple applications into one repository.
 
 
 
 
 
 
 
 
 
 
 
 
 
 























